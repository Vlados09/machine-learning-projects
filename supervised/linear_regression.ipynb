{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Brief \n",
    "\n",
    "## Deadline: Tuesday, October 29, 2019 at 14:00 hrs\n",
    "\n",
    "## Number of marks available: 20\n",
    "\n",
    "## Scope: Sessions 1 to 5\n",
    "\n",
    "### How and what to submit\n",
    "\n",
    "A. Submit a Jupyter Notebook named COM4509-6509_Assignment_1_UCard_XXXXXXXXX.ipynb where XXXXXXXXX refers to your UCard number.\n",
    "\n",
    "B. Upload the notebook file to MOLE before the deadline above.\n",
    "\n",
    "C. **NO DATA UPLOAD**: Please do not upload the data files used. We have a copy already. \n",
    "\n",
    "\n",
    "### Assessment Criteria \n",
    "\n",
    "* Being able to express an objective function and its gradients in matrix form.\n",
    "\n",
    "* Being able to use numpy and pandas to preprocess a dataset.\n",
    "\n",
    "* Being able to use numpy to build a machine learning pipeline for supervised learning. \n",
    "\n",
    "\n",
    "### Late submissions\n",
    "\n",
    "We follow Department's guidelines about late submissions, i.e., a deduction of 5% of the mark each working day the work is late after the deadline. NO late submission will be marked one week after the deadline because we will release a solution by then. Please read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/assessment/late-submission?pli=1&authuser=1). \n",
    "\n",
    "### Use of unfair means \n",
    "\n",
    "**\"Any form of unfair means is treated as a serious academic offence and action may be taken under the Discipline Regulations.\"** (from the MSc Handbook). Please carefully read [this link](https://sites.google.com/sheffield.ac.uk/compgtstudenthandbook/menu/referencing-unfair-means?pli=1&authuser=1) on what constitutes Unfair Means if not sure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularisation for Linear Regression\n",
    "\n",
    "Regularisation is a technique commonly used in Machine Learning to prevent overfitting. It consists on adding terms to the objective function such that the optimisation procedure avoids solutions that just learn the training data. Popular techniques for regularisation in Supervised Learning include Lasso Regression, Ridge Regression and the Elastic Net. \n",
    "\n",
    "In this Assignment, you will be looking at Ridge Regression and devising equations to optimise the objective function in Ridge Regression using two methods: a closed-form derivation and the update rules for stochastic gradient descent. You will then use those update rules for making predictions on a Air Quaility dataset.\n",
    "\n",
    "## Ridge Regression\n",
    "\n",
    "Let us start with a data set for training $\\mathcal{D} = \\{\\mathbf{y}, \\mathbf{X}\\}$, where the vector $\\mathbf{y}=[y_1, \\cdots, y_n]^{\\top}$ and $\\mathbf{X}$ is the design matrix from Lab 3, this is, \n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathbf{X} = \n",
    "                \\begin{bmatrix}\n",
    "                        1 & x_{1,1} & \\cdots & x_{1, D}\\\\\n",
    "                        1 & x_{2,1} & \\cdots & x_{2, D}\\\\\n",
    "                   \\vdots &  \\vdots\\\\\n",
    "                        1 & x_{n,1} & \\cdots & x_{n, D}\n",
    "                \\end{bmatrix}\n",
    "               = \n",
    "               \\begin{bmatrix}\n",
    "                      \\mathbf{x}_1^{\\top}\\\\\n",
    "                       \\mathbf{x}_2^{\\top}\\\\\n",
    "                          \\vdots\\\\\n",
    "                        \\mathbf{x}_n^{\\top}\n",
    "                \\end{bmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Our predictive model is going to be a linear model\n",
    "\n",
    "$$ f(\\mathbf{x}_i) = \\mathbf{w}^{\\top}\\mathbf{x}_i,$$\n",
    "\n",
    "where $\\mathbf{w} = [w_0\\; w_1\\; \\cdots \\; w_D]^{\\top}$.\n",
    "\n",
    "The **objetive function** we are going to use has the following form\n",
    "\n",
    "$$ J(\\mathbf{w}, \\alpha) = \\frac{1}{n}\\sum_{i=1}^n (y_i - f(\\mathbf{x}_i))^2 + \\frac{\\alpha}{2}\\sum_{j=0}^D w_j^2,$$\n",
    "\n",
    "where $\\alpha>0$ is known as the *regularisation* parameter.\n",
    "\n",
    "The first term on the right-hand side (rhs) of the expression for $J(\\mathbf{w}, \\alpha)$ is very similar to the least-squares objective function we have seen before, for example in Lab 3. The only difference is on the term $\\frac{1}{n}$ that we use to normalise the objective with respect to the number of observations in the dataset. \n",
    "\n",
    "The first term on the rhs is what we call the \"fitting\" term whereas the second term in the expression is the regularisation term. Given $\\alpha$, the two terms in the expression have different purposes. The first term is looking for a value of $\\mathbf{w}$ that leads the squared-errors to zero. While doing this, $\\mathbf{w}$ can take any value and lead to a solution that it is only good for the training data but perhaps not for the test data. The second term is regularising the behavior of the first term by driving the $\\mathbf{w}$ towards zero. By doing this, it restricts the possible set of values that $\\mathbf{w}$ might take according to the first term. The value that we use for $\\alpha$ will allow a compromise between a value of $\\mathbf{w}$ that exactly fits the data (first term) or a value of $\\mathbf{w}$ that does not grow too much (second term).\n",
    "\n",
    "This type of regularisation has different names: ridge regression, Tikhonov regularisation or $\\ell_2$ norm regularisation. \n",
    "\n",
    "### Question 1: $J(\\mathbf{w}, \\alpha)$ in matrix form (2 marks)\n",
    "\n",
    "Write the expression for $J(\\mathbf{w}, \\alpha)$ in matrix form. Include ALL the steps necessary to reach the expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 Answer\n",
    "First we can re-write the $f(\\mathbf{x}_i)$ fucntion as a matrix multipltication to represent multiple inner proucts between individual input vecotrs and parameters:\n",
    "\n",
    "$$\n",
    "f(x_i) = \\mathbf{w}^\\top x_i = (\\mathbf{w}^\\top x_i)^\\top = x^\\top_i\\mathbf{w}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \\begin{bmatrix}f(x_1)\\\\f(x_2)\\\\ \\vdots \\\\ f(x_n)\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{Xw}\n",
    "$$\n",
    "\n",
    "Using the following identity:\n",
    "$$\n",
    "a = \\sum_{i=1}^{k} b^2_i = \\mathbf{b}^\\top\\mathbf{b},\n",
    "$$\n",
    "\n",
    "we can derive:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}, \\alpha) = \\frac{1}{N}(\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f}) + \\frac{\\alpha}{2}(\\mathbf{w^\\top w})\n",
    "$$\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}, \\alpha) = \\frac{1}{N}(\\mathbf{y} - \\mathbf{Xw})^\\top(\\mathbf{y} - \\mathbf{Xw}) + \\frac{\\alpha}{2}(\\mathbf{w^\\top w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the objective function with respect to $\\mathbf{w}$\n",
    "\n",
    "There are two ways we can optimise the objective function with respect to $\\mathbf{w}$. The first one leads to a closed form expression for $\\mathbf{w}$ and the second one using an iterative optimisation procedure that updates the value of $\\mathbf{w}$ at each iteration by using the gradient of the objective function with respect to $\\mathbf{w}$,\n",
    "$$\n",
    "\\mathbf{w}_{\\text{new}} = \\mathbf{w}_{\\text{old}} - \\eta \\frac{d J(\\mathbf{w}, \\alpha)}{d\\mathbf{w}},\n",
    "$$\n",
    "where $\\eta$ is the *learning rate* parameter and $\\frac{d J(\\mathbf{w}, \\alpha)}{d\\mathbf{w}}$ is the gradient of the objective function.\n",
    "\n",
    "### Question 2: Derivative of $J(\\mathbf{w}, \\alpha)$ wrt $\\mathbf{w}$ (2 marks)\n",
    "\n",
    "Find the closed-form expression for $\\mathbf{w}$ by taking the derivative of $J(\\mathbf{w}, \\alpha)$ with respect to \n",
    "$\\mathbf{w}$, equating to zero and solving for $\\mathbf{w}$. Write the expression in matrix form. \n",
    "\n",
    "Also, write down the specific update rule for $\\mathbf{w}_{\\text{new}}$ by using the equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 Answer\n",
    "\n",
    "First we multiply out the brackets using the following identity:\n",
    "\n",
    "$$\n",
    "(\\mathbf{a} - \\mathbf{b})^\\top (\\mathbf{c} - \\mathbf{d}) = \\mathbf{a}^\\top \\mathbf{c} - \\mathbf{a}^\\top \\mathbf{d} - \\mathbf{b}^\\top \\mathbf{c} + \\mathbf{b}^\\top \\mathbf{d}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{a} = \\mathbf{c} = \\mathbf{y}$ and $\\mathbf{b}=\\mathbf{d} = \\mathbf{X}\\mathbf{w}$\n",
    "\n",
    "$$\n",
    "(\\mathbf{y} - \\mathbf{Xw})^\\top(\\mathbf{y} - \\mathbf{Xw}) = \\mathbf{y}^\\top\\mathbf{y} - 2\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w} + \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w}\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}, \\alpha) = \\frac{1}{N}(\\mathbf{y}^\\top\\mathbf{y} - 2\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w} + \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w}) + \\frac{\\alpha}{2}(\\mathbf{w^\\top w})\n",
    "$$\n",
    "\n",
    "Now we can differentate two terms on the right hand side seperately using the following identities:\n",
    "\n",
    "$$\n",
    "\\frac{d(w^\\top x)}{dw} = x | \\frac{d(x^\\top w)}{dw} = x | \\frac{d(w^\\top w)}{dw} = 2w | \\frac{d(w^\\top Cw)}{dw} = 2Cw\n",
    "$$\n",
    "\n",
    "And knowing that $\\mathbf{X^\\top X}$ is symmetric, we get:\n",
    "\n",
    "$$\n",
    "\\frac{d J(\\mathbf{w}, \\alpha)}{d\\mathbf{w}} = \\frac{1}{N}(-2\\mathbf{X^\\top y} + 2\\mathbf{X^\\top Xw}) + \\frac{\\alpha}{2}(2\\mathbf{w})\n",
    "$$\n",
    "\n",
    "Rearanging and simplifying:\n",
    "\n",
    "$$\n",
    "\\frac{d J(\\mathbf{w}, \\alpha)}{d\\mathbf{w}} = \\frac{2}{N}(\\mathbf{X^\\top Xw} - \\mathbf{X^\\top y}) + \\alpha\\mathbf{w}\n",
    "$$\n",
    "\n",
    "Thus specific update rule for $\\mathbf{w}_{\\text{new}}$ would be:\n",
    "\n",
    "$$\n",
    "\\mathbf{w}_{\\text{new}} = \\mathbf{w}_{\\text{old}} - \\eta(\\frac{2}{N}(\\mathbf{X^\\top Xw_{\\text{old}}} - \\mathbf{X^\\top y}) + \\alpha\\mathbf{w_{\\text{old}}})\n",
    "$$\n",
    "\n",
    "As for the closed form expression we equate the derived gradient to 0 and rearange for $\\mathbf{w}$:\n",
    "\n",
    "$$\n",
    "\\frac{2}{N}(\\mathbf{X^\\top Xw} - \\mathbf{X^\\top y}) + \\alpha\\mathbf{w} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{2}{N}(\\mathbf{X^\\top Xw}) - \\frac{2}{N}(\\mathbf{X^\\top y}) + \\alpha\\mathbf{w} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{X^\\top Xw} - \\mathbf{X^\\top y} + \\frac{N\\alpha}{2}\\mathbf{w} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{X^\\top Xw} + \\frac{N\\alpha}{2}\\mathbf{w} = \\mathbf{X^\\top y}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(\\mathbf{X^\\top X} + \\frac{N\\alpha}{2}\\mathbf{I})\\mathbf{w} = \\mathbf{X^\\top y}\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "$$\n",
    "\\mathbf{w^*} = (\\mathbf{X^\\top X} + \\frac{N\\alpha}{2}\\mathbf{I})^{-1}\\mathbf{X^\\top y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ridge regression to predict air quality\n",
    "\n",
    "Our dataset comes from a popular machine learning repository that hosts open source datasets for educational and research purposes, the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php). We are going to use ridge regression for predicting air quality. The description of the dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/Air+Quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading  https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip -> ./AirQualityUCI.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================    ]   1.320/1.472MB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \r",
      "[===========================   ]   1.328/1.472MB"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================]   1.472/1.472MB                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n"
     ]
    }
   ],
   "source": [
    "import pods\n",
    "pods.util.download_url('https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip')\n",
    "import zipfile\n",
    "zip = zipfile.ZipFile('./AirQualityUCI.zip', 'r')\n",
    "for name in zip.namelist():\n",
    "    zip.extract(name, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The .csv version of the file has some typing issues, so we use the excel version\n",
    "air_quality = pd.read_excel('./AirQualityUCI.xlsx', usecols=range(2,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some of the rows in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3702</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>-200</td>\n",
       "      <td>7.886653</td>\n",
       "      <td>894.50</td>\n",
       "      <td>58.0</td>\n",
       "      <td>744.75</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1726.50</td>\n",
       "      <td>882.00</td>\n",
       "      <td>27.300</td>\n",
       "      <td>57.775000</td>\n",
       "      <td>2.064634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4133</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1160.5</td>\n",
       "      <td>-200</td>\n",
       "      <td>12.214164</td>\n",
       "      <td>1057.00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>613.00</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1764.00</td>\n",
       "      <td>1026.00</td>\n",
       "      <td>25.125</td>\n",
       "      <td>51.525000</td>\n",
       "      <td>1.620955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1310.0</td>\n",
       "      <td>79</td>\n",
       "      <td>8.826223</td>\n",
       "      <td>932.50</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1081.75</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1646.50</td>\n",
       "      <td>946.25</td>\n",
       "      <td>8.325</td>\n",
       "      <td>79.799999</td>\n",
       "      <td>0.877784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7603</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1516.5</td>\n",
       "      <td>-200</td>\n",
       "      <td>23.959596</td>\n",
       "      <td>1402.50</td>\n",
       "      <td>827.1</td>\n",
       "      <td>451.00</td>\n",
       "      <td>197.8</td>\n",
       "      <td>1578.50</td>\n",
       "      <td>2194.75</td>\n",
       "      <td>11.100</td>\n",
       "      <td>51.449999</td>\n",
       "      <td>0.679006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2484</td>\n",
       "      <td>0.9</td>\n",
       "      <td>889.5</td>\n",
       "      <td>-200</td>\n",
       "      <td>6.412912</td>\n",
       "      <td>830.75</td>\n",
       "      <td>93.0</td>\n",
       "      <td>922.00</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1594.25</td>\n",
       "      <td>825.75</td>\n",
       "      <td>17.750</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>1.137511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CO(GT)  PT08.S1(CO)  NMHC(GT)   C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  \\\n",
       "3702     1.6       1053.0      -200   7.886653         894.50     58.0   \n",
       "4133  -200.0       1160.5      -200  12.214164        1057.00   -200.0   \n",
       "21       2.2       1310.0        79   8.826223         932.50    184.0   \n",
       "7603     5.0       1516.5      -200  23.959596        1402.50    827.1   \n",
       "2484     0.9        889.5      -200   6.412912         830.75     93.0   \n",
       "\n",
       "      PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)       T         RH  \\\n",
       "3702        744.75     46.0       1726.50       882.00  27.300  57.775000   \n",
       "4133        613.00   -200.0       1764.00      1026.00  25.125  51.525000   \n",
       "21         1081.75    126.0       1646.50       946.25   8.325  79.799999   \n",
       "7603        451.00    197.8       1578.50      2194.75  11.100  51.449999   \n",
       "2484        922.00     67.0       1594.25       825.75  17.750  56.500000   \n",
       "\n",
       "            AH  \n",
       "3702  2.064634  \n",
       "4133  1.620955  \n",
       "21    0.877784  \n",
       "7603  0.679006  \n",
       "2484  1.137511  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_quality.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable corresponds to the CO(GT) variable of the first column. The following columns correspond to the variables in the feature vectors, *e.g.*, PT08.S1(CO) is $x_1$ up until AH which is $x_D$. The original dataset also has a date and a time columns that we are not going to use in this assignment.\n",
    "\n",
    "Before designing our predictive model, we need to think about three stages: the preprocessing stage, the training stage and the validation stage. The three stages are interconnected and *it is important to remember that the testing data that we use for validation has to be set aside before preprocessing*. Any preprocessing that you do has to be done only on the training data and several key statistics need to be saved for the test stage.\n",
    "\n",
    "Separating the dataset into training and test before any preprocessing has happened help us to recreate the real world scenario where we will deploy our system and for which the data will come without any preprocessing.\n",
    "\n",
    "We are going to use *hold-out validation* for testing our predictive model so we need to separate the dataset into a training set and a test set.\n",
    "\n",
    "### Question 3: Splitting the dataset (1 mark)\n",
    "\n",
    "Split the dataset into a training set and a test set. The training set should have 70% of the total observations and the test set, the 30%. For making the random selection make sure that you use a random seed that corresponds to the last five digits of your student UCard. Make sure that you comment your code.\n",
    "\n",
    "#### Question 3 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, labels=None, random_state=52997, train_size=0.7):\n",
    "    \"\"\" Split data into a training and test set\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        The pd.DataFrame object to be split\n",
    "    labels\n",
    "        Optional parameter to split the labels if passed\n",
    "    random_state\n",
    "        Randomizes splitting, set to last 5 numbers on Ucard by default\n",
    "    train_size\n",
    "        Proportion of data for training set, 70% by default\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train, test\n",
    "        Return just train and test set if labels were not provided\n",
    "        \n",
    "    train, test, y_train, y_test\n",
    "        Also return labels for train and test set if provided.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample 70% of the data:\n",
    "    train = data.sample(frac=train_size, random_state=random_state)\n",
    "    \n",
    "    # Delete the train data form original DataFrame:\n",
    "    test = data.drop(train.index)\n",
    "    \n",
    "    if labels is None:\n",
    "        return train, test\n",
    "    else:\n",
    "        y_train, y_test = y.loc[train.index], labels.loc[test.index]\n",
    "        return train, test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(air_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "The dataset has missing values tagged with a -200 value. Before doing any work with the training data, we want to make sure that we deal properly with the missing values. \n",
    "\n",
    "### Question 4: Missing values (3 marks)\n",
    "\n",
    "Make some exploratory analysis on the number of missing values per column in the training data. \n",
    "\n",
    "* Remove the rows for which the target feature has missing values. We are doing supervised learning so we need all our data observations to have known target values.\n",
    "\n",
    "* Remove features with more than 20% of missing values. For all the other features with missing values, use the mean value of the non-missing values for imputation.\n",
    "\n",
    "#### Question 4 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, features=None, fill=None):\n",
    "    \"\"\" Function for preprocessing the data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data\n",
    "        The pd.DataFrame object to be preprocessed\n",
    "        Has to contain 'CO(GT)' as one of the columns\n",
    "    features\n",
    "        Optional parameter denoting which features to keep\n",
    "        If not provided features with over 20% missing values are droped\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data\n",
    "        Preprocessed pd.DataFrame object\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace the -200 values with NaNs:\n",
    "    data.where(data != -200, inplace=True)\n",
    "\n",
    "    # Remove the rows with missing values in target column:\n",
    "    data.dropna(subset=['CO(GT)'], inplace=True)\n",
    "\n",
    "    # Remove the features with more than 20% missing values:\n",
    "    if features is None:\n",
    "        data.dropna(axis=1, thresh=(data.shape[0]*0.8), inplace=True)\n",
    "    else:\n",
    "        data = data[features]\n",
    "\n",
    "    # Fill missing values:\n",
    "    if fill is None:\n",
    "        data.fillna(data.mean(), inplace=True)\n",
    "    else:\n",
    "        data.fillna(fill, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Normalising the training data (2 marks)\n",
    "\n",
    "Now that you have removed the missing data, we need to normalise the input vectors. \n",
    "\n",
    "* Explain in a sentence why do you need to normalise the input features for this dataset.\n",
    "\n",
    "* Normalise the training data by substracting the mean value for each feature and dividing the result by the standard deviation of each feature. Keep the mean values and standard deviations, you will need them at test time.\n",
    "\n",
    "#### Question 5 Answer\n",
    "\n",
    "Makes training less sensative to the scale of features and stabilizes the regularization. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes sense to split data here since we only have to normalise the input data.\n",
    "y = train['CO(GT)']\n",
    "X = train.drop(['CO(GT)'], axis=1)\n",
    "\n",
    "# Normalise the input features:\n",
    "train_mean = X.mean()\n",
    "train_std = X.std()\n",
    "X_norm_1 = (X - train_mean)/train_std\n",
    "\n",
    "X_norm = np.empty(X.shape)\n",
    "for i in range(X.shape[1]):\n",
    "    X_norm[:, i] = (X_norm[:, i] - train_mean[i])/train_std[i] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.11210432e+03 1.03230852e+01 9.48855924e+02 2.57872006e+02\n",
      " 8.26943338e+02 1.14945219e+02 1.44454942e+03 1.05034943e+03\n",
      " 1.76404829e+01 4.92440213e+01 9.85834018e-01]\n",
      "[2.14718531e+02 7.26477585e+00 2.59757660e+02 2.12882143e+02\n",
      " 2.53762733e+02 4.73058636e+01 3.41802289e+02 4.00211168e+02\n",
      " 8.63732418e+00 1.70366159e+01 3.90495687e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  -5.15422975,   11.71028481,   -3.6528506 , ...,  -25.58602627,\n",
       "          -4.90698047,  422.30900634],\n",
       "       [  -5.53728937,  -39.87423858,   -3.83515252, ...,   37.02016851,\n",
       "         -12.88978648, -281.92412425],\n",
       "       [  -5.61529847,   10.50584297,   -2.98243464, ...,   37.65693979,\n",
       "          -8.44348093,  948.56321847],\n",
       "       ...,\n",
       "       [  -5.1798895 ,   -1.42097779,   -3.65193715, ...,   -2.05660936,\n",
       "          -2.88948137,   -1.96571906],\n",
       "       [  -5.17676647,   -1.39040624,   -3.65379251, ...,   -2.08125713,\n",
       "          -2.89048139,   -2.85167146],\n",
       "       [  -5.18036631,   -1.50059734,   -3.65301557, ...,   -2.10055313,\n",
       "          -2.9326304 ,   -3.60723974]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_mean.values)\n",
    "print(train_std.values)\n",
    "X_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation stages\n",
    "\n",
    "We have now curated our training data by removing data observations and features with a large amount of missing values. We have also normalised the feature vectors. We are now in a good position to work on developing the prediction model and validating it. We will use both the closed form expression for $\\mathbf{w}$ and gradient descent for iterative optimisation. \n",
    "\n",
    "We first organise the dataframe into the vector of targets $\\mathbf{y}$ and the design matrix $\\mathbf{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here to get y and X\n",
    "y = y\n",
    "X['Eins'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: training with closed form expression for $\\mathbf{w}$ (3 marks)\n",
    "\n",
    "To find the optimal value of $\\mathbf{w}$ using the closed form expression that you derived before, we need to know the value of the regularisation parameter $\\alpha$ in advance. We will determine the value by using part of the training data for finding the parameters $\\mathbf{w}$ and another part of the training data to choose the best $\\alpha$ from a set of predefined values.\n",
    "\n",
    "* Use `np.logspace(start, stop, num)` to create a set of values for $\\alpha$ in log scale. Use the following parameters `start=-3`, `stop=2` and `num=20`. \n",
    "\n",
    "* Randomly split the training data into what is properly called the training set and the validation set. As before, make sure that you use a random seed that corresponds to the last five digits of your student UCard. Use 70% of the data for the training set and 30% of the data for the validation set.\n",
    "\n",
    "* For each value that you have for $\\alpha$ from the previous step, use the training set to compute $\\mathbf{w}$ and then measure the mean-squared error (MSE) over the validation data. After this, you will have `num=20` MSE values. Choose the value of $\\alpha$ that leads to the lower MSE and save it. You will use it at the test stage.\n",
    "\n",
    "* What was the best value of $\\alpha$? Is there any explanation for that?\n",
    "\n",
    "#### Question 6 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form(X, y, alpha):\n",
    "    \"\"\" Calculates closed form solution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Input features\n",
    "    y\n",
    "        Output labels\n",
    "    alpha\n",
    "        Regularization parameter\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w\n",
    "        Optimal value w*\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    N, n_features = X.shape\n",
    "    linear1 = ((X.T @ X) + (((N * alpha) / 2) * np.eye(n_features)))\n",
    "    linear2 = X.T @ y \n",
    "    w = np.linalg.solve(linear1, linear2)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(actual, pred):\n",
    "    \"\"\" Calculates mean squared error.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual\n",
    "        Output labels\n",
    "    pred\n",
    "        Preidctions made by the model\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mse\n",
    "        Mean Square Error of predictions\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    mse = np.mean(np.square(actual - pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_alpha(X, y):\n",
    "    \n",
    "    alpha_range = np.logspace(-3, 2, 100)\n",
    "\n",
    "    # Split data into train and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, labels=y)\n",
    "\n",
    "    val_errors = []\n",
    "    for alpha in alpha_range:\n",
    "        w = closed_form(X_train, y_train, alpha)\n",
    "        \n",
    "        val_pred = X_val @ w\n",
    "        val_mse = compute_mse(y_val, val_pred)\n",
    "        val_errors.append(val_mse)\n",
    "         \n",
    "    # Plot error vs alpha:\n",
    "    fig, ax = plt.subplots(2)\n",
    "    \n",
    "    for i in range(len(ax)):\n",
    "        ax[i].plot(alpha_range, val_errors)\n",
    "        ax[i].set_xlabel('Alpha')\n",
    "        ax[i].set_ylabel('Error (mse)')     \n",
    "    ax[0].set_title('Error vs Alpha')\n",
    "    ax[1].set(xlim=(0, 0.1), ylim=(0.23, 0.24)) # Scaled plot\n",
    "    \n",
    "    return alpha_range[np.argmin(val_errors)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal alpha is 0.029\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt_alpha = optimal_alpha(X, y)\n",
    "print(f'Optimal alpha is {opt_alpha:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As alpha increases the error becomes larger tending towards similar values as if the parameters were initialised randomly. This is caused by unstable update of the parameters due to regularazation becoming dominant value. So alpha has to be small to ensure the parameters are not over regularized but it has to be over 0 to limit the complexity of the model to an extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7: validation with the closed form expression for $\\mathbf{w}$ (2 marks)\n",
    "\n",
    "We are going to deal now with the test data to perform the validation of the model. Remember that the test data might also contain missing values in the target variable and in the input features.\n",
    "\n",
    "* Remove the rows of the test data for which the labels have missing values. \n",
    "* If you remove any feature at the training stage, you also need to remove the same features from the test stage.\n",
    "* Replace the missing values on each feature variables with the mean value you computed in the training data.\n",
    "* Normalise the test data using the means and standard deviations computed from the training data\n",
    "* Compute again $\\mathbf{w}$ for the value of $\\alpha$ that best performed on the validation set using ALL the training data (not all the training set).\n",
    "* Report the MSE on the preprocessed test data and an histogram with the absolute error.\n",
    "* Does the regularisation have any effect on the model? Explain your answer.\n",
    "\n",
    "#### Question 7 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(test_data, train, w, display=False):\n",
    "    \"\"\" Function for validating the model. \n",
    "    Preprocessed the training data and makes predictions\n",
    "    Then calculates mse and absolute error and displays results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_data\n",
    "        Unprocessed test data passed as pd.DataFrame\n",
    "    train\n",
    "        Processed train data (pd.DataFrame)\n",
    "    w\n",
    "        Parameter values calculated durning training\n",
    "    display\n",
    "        If set to True will plot absolute error histogram\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess and Normalise the test data:\n",
    "    test_data = preprocess(test_data, features=train.columns, fill=train.mean())\n",
    "    y_test = test_data['CO(GT)']\n",
    "    X_test = test_data.drop(['CO(GT)'], axis=1)\n",
    "    X_test = (X_test - train_mean) / train_std\n",
    "    X_test['Eins'] = 1\n",
    "    \n",
    "    # Make predictions and compute mse error:\n",
    "    pred = X_test @ w\n",
    "    mse = compute_mse(y_test, pred)\n",
    "    print(f'Mean squared error for the test data is {mse:.4}')\n",
    "    \n",
    "    # Compute and plot the absoulte error:\n",
    "    abs_error = np.abs(y_test - pred)\n",
    "    mae = abs_error.sum()/abs_error.shape[0]\n",
    "    print(f'Mean absolute error for the test data is {mae:.4}')\n",
    "    \n",
    "    if display:\n",
    "        abs_error.hist(bins=100)\n",
    "        plt.title('Absolute Error Histogram')\n",
    "        plt.xlabel('Error (absolute)')\n",
    "        plt.ylabel('N of Occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Lucker/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for the test data is 0.2195\n",
      "Mean absolute error for the test data is 0.3047\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Validation with optimal alpha calculated above\n",
    "w_closed = closed_form(X, y, opt_alpha) \n",
    "validate_model(test, train, w_closed, display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for the test data is 0.2194\n",
      "Mean absolute error for the test data is 0.3028\n"
     ]
    }
   ],
   "source": [
    "# Validation with alpha set to 0 (i.e. no regularization)\n",
    "w = closed_form(X, y, 0)\n",
    "validate_model(test, train, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory regularization does have an effect on the model, limiting its complexity which allows for a greater generalisation. However, results above suggest that regularization does not improve the performance of the model on testing set. The difference however is so small that could be attributed to statistical noise or it could imply that regularisation is not effective for computing the optimal parameter directly trough the closed form expression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: training with gradient descent and validation (5 marks)\n",
    "\n",
    "\n",
    "Use gradient descent to iteratively compute the value of $\\mathbf{w}_{\\text{new}}$. Instead of using all the training set to compute the gradient, use a subset of $B$ datapoints in the training set. This is sometimes called minibatch gradient descent where $B$ is the size of the minibacth. When using gradient descent with minibatches, you need to find the best values for three parameters: $\\eta$, the learning rate, $B$, the number of datapoints in the minibatch and $\\alpha$, the regularisation parameter.\n",
    "\n",
    "* As you did on Question 6, create a grid of values for the parameters $\\alpha$ and $\\eta$ using `np.logspace` and a grid of values for $B$ using np.linspace. Because you need to find \n",
    " three parameters, start with `num=5` and see if you can increase it.\n",
    "\n",
    "* Use the same training set and validation set that you used in Question 6.\n",
    "\n",
    "* For each value that you have of $\\alpha$, $\\eta$ and $B$ from the previous step, use the training set to compute $\\mathbf{w}$ using minibatch gradient descent and then measure the MSE over the validation data. For the minibatch gradient descent choose to stop the iterative procedure after $500$ iterations.\n",
    "\n",
    "* Choose the values of $\\alpha$, $\\eta$ and $B$ that lead to the lower MSE and save them. You will use them at the test stage.\n",
    "\n",
    "*3 marks of out of the 5 marks*\n",
    "\n",
    "\n",
    "* Use the test set from Question 7 and provide the MSE obtained by having used minibatch training with the best values for $\\alpha$, $\\eta$ and $B$ over the WHOLE training data (not only the training set).\n",
    "\n",
    "* Compare the performance of the closed form solution and the minibatch solution. Are the performances similar? Are the parameters $\\mathbf{w}$ and $\\alpha$ similar in both approaches? Please comment on both questions.\n",
    "\n",
    "*2 marks of out of the 5 marks*\n",
    "\n",
    "#### Question 8 Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, alpha):\n",
    "    \"\"\" Calculate the gradient using equation derived above\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "        Input features\n",
    "    y\n",
    "        Output labels\n",
    "    w \n",
    "        parameter values\n",
    "    alpha\n",
    "        regularization parameter\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    dw\n",
    "        gradient for upading parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    dw = (2 / N) * ((X.T @ X @ w) - (X.T @ y)) + (alpha * w)\n",
    "    \n",
    "    return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MBGD(X, y, lr=0.001, alpha=0.01, batch_size=32, epochs=500, train_size=0.7):\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, labels=y, train_size=train_size)\n",
    "    N, n_features = X_train.shape\n",
    "     \n",
    "    np.random.seed(52997) # Ensures weights are always initialised to same values\n",
    "    w = np.random.uniform(-0.01, 0.01, size=(n_features))\n",
    "    \n",
    "    val_errors = []\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        # Shuffle the data using the random sample method in train_test_split\n",
    "        shuff_X, _, shuff_y, _ = train_test_split(X_train, labels=y_train, train_size=1, random_state=epoch)\n",
    "        \n",
    "        # Split the data into minibatches\n",
    "        split_X = np.array_split(shuff_X.values, int(N/batch_size))\n",
    "        split_y = np.array_split(shuff_y.values, int(N/batch_size))\n",
    "        \n",
    "        for i in range(len(split_X)):   \n",
    "            X_i, y_i = split_X[i], split_y[i]\n",
    "            dw = compute_gradient(X_i, y_i, w, alpha)\n",
    "            w -= (lr * dw)\n",
    "        \n",
    "        # Compute valuation error if not full training set is used\n",
    "        if train_size < 1:\n",
    "            val_pred = X_val @ w\n",
    "            val_error = compute_mse(y_val, val_pred)\n",
    "            val_errors.append(val_error)\n",
    "                \n",
    "    return w, val_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New minimal error: 0.2348. Improved by 0.7652\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.001, 'batch_size': 32}\n",
      "New minimal error: 0.2346. Improved by 0.0001834\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.001, 'batch_size': 64}\n",
      "New minimal error: 0.2336. Improved by 0.001005\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.001, 'batch_size': 128}\n",
      "New minimal error: 0.232. Improved by 0.001554\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.001, 'batch_size': 256}\n",
      "New minimal error: 0.2315. Improved by 0.0004954\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.001, 'batch_size': 512}\n",
      "New minimal error: 0.2315. Improved by 6.721e-06\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.0016681005372000592, 'batch_size': 512}\n",
      "New minimal error: 0.2315. Improved by 8.699e-06\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.0027825594022071257, 'batch_size': 512}\n",
      "New minimal error: 0.2315. Improved by 7.547e-06\n",
      "With following parameters: {'lr': 0.001, 'alpha': 0.004641588833612777, 'batch_size': 512}\n",
      "New minimal error: 0.2315. Improved by 2.111e-05\n",
      "With following parameters: {'lr': 0.001291549665014884, 'alpha': 0.0027825594022071257, 'batch_size': 512}\n",
      "New minimal error: 0.2315. Improved by 3.562e-05\n",
      "With following parameters: {'lr': 0.001291549665014884, 'alpha': 0.004641588833612777, 'batch_size': 512}\n",
      "New minimal error: 0.2314. Improved by 3.902e-05\n",
      "With following parameters: {'lr': 0.001291549665014884, 'alpha': 0.007742636826811269, 'batch_size': 512}\n",
      "New minimal error: 0.2314. Improved by 8.986e-06\n",
      "With following parameters: {'lr': 0.001291549665014884, 'alpha': 0.01291549665014884, 'batch_size': 512}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b378402d7a70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mopt_pars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize_mbgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-b378402d7a70>\u001b[0m in \u001b[0;36moptimize_mbgd\u001b[0;34m(X, y)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malpha_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_range\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMBGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                     \u001b[0mlast_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlast_error\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-814c02109121>\u001b[0m in \u001b[0;36mMBGD\u001b[0;34m(X, y, lr, alpha, batch_size, epochs, train_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Shuffle the data using the random sample method in train_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mshuff_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuff_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Split the data into minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-68e0570c50e6>\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(data, labels, random_state, train_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Delete the train data form original DataFrame:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m         )\n\u001b[1;32m   4104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3947\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m         \u001b[0;31m# Case for non-unique axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3959\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3961\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3963\u001b[0m     def drop(\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4512\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4513\u001b[0m         return self._reindex_axes(\n\u001b[0;32m-> 4514\u001b[0;31m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4515\u001b[0m         ).__finalize__(self)\n\u001b[1;32m   4516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   3847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3848\u001b[0m             frame = frame._reindex_index(\n\u001b[0;32m-> 3849\u001b[0;31m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3850\u001b[0m             )\n\u001b[1;32m   3851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[0;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   3869\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3870\u001b[0m             \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3871\u001b[0;31m             \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3872\u001b[0m         )\n\u001b[1;32m   3873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   4581\u001b[0m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mlai/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, axes, copy, dtype, fastpath)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_copy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_item_cache\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def optimize_mbgd(X, y):\n",
    "    \n",
    "    lr_range = np.logspace(-3, -2, 10)\n",
    "    alpha_range = np.logspace(-3, -1, 10)\n",
    "    batch_range = np.power(2, range(5,10))\n",
    "    \n",
    "    min_error = 1\n",
    "    for lr in lr_range:\n",
    "        for alpha in alpha_range:\n",
    "            for batch in batch_range:\n",
    "                    w, errors = MBGD(X, y, lr=lr, alpha=alpha, batch_size=batch)\n",
    "                    last_error = errors[-1]\n",
    "                    if last_error < min_error:\n",
    "                        print(f'New minimal error: {last_error:.4}. Improved by {(min_error - last_error):.4}')\n",
    "                        min_error = last_error\n",
    "                        pars = dict(lr=lr, alpha=alpha, batch_size=batch)\n",
    "                        print(f'With following parameters: {pars}')\n",
    "    return pars\n",
    "\n",
    "opt_pars = optimize_mbgd(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for the test data is 0.2189\n",
      "Mean absolute error for the test data is 0.3033\n",
      "\n",
      "Mean value for the minibatch parameters is 0.2987 and for closed form is 0.2986\n",
      "The optimal alpha parameter for the minibatch is 0.008 and for closed form is 0.029\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# From the code above optimal parameters were found to be: (lr and alpha are round to 3d.p.)\n",
    "opt_pars = {'lr': 0.006, 'alpha': 0.008, 'batch_size': 512}\n",
    "\n",
    "w, _ = MBGD(X, y, train_size=1, **opt_pars)\n",
    "validate_model(test, train, w)\n",
    "\n",
    "# Comparing the weights and alpha:\n",
    "\n",
    "# Plot the bar chart for absolute values of parameters:\n",
    "labels = X.columns\n",
    "x = np.arange(len(labels)) \n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "rects1 = ax.bar(x - width/2, np.abs(w), width, label='MBGD')\n",
    "rects2 = ax.bar(x + width/2, np.abs(w_closed), width, label='Closed Form')\n",
    "\n",
    "ax.set_ylabel('Parameter Values')\n",
    "ax.set_title('Comparison of w for minibatch and closed form')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "print(f'\\nMean value for the minibatch parameters is {np.mean(w):.4} and for closed form is {np.mean(w_closed):.4}')\n",
    "print(f\"The optimal alpha parameter for the minibatch is {opt_pars['alpha']:.3} and for closed form is {opt_alpha:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for the test data is 0.2191\n",
      "Mean absolute error for the test data is 0.3032\n"
     ]
    }
   ],
   "source": [
    "# Testing the model without regularization:\n",
    "opt_pars['alpha'] = 0\n",
    "w, _ = MBGD(X, y, train_size=1, **opt_pars)\n",
    "validate_model(test, train, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of the minibatch gradient descent is sligtly better on the test set for both regularised and non-regularised approaches, which suggests that the model was able to generalise better just because of the minibatch. The effect of regularization is also more positive showing slight improvement in performance. Again, those difference are insignificant and could be attributed to noise. \n",
    "\n",
    "The values for $\\mathbf{w}$ are very simillar for both models with MBGD having a slightly higher value on average. The $\\alpha$ parameter on the other hand is very different between the two models. This is likely because of the difference in frequency and scale of updates, where in closed form we peform it in a single calculation but with minibatch it is done over numerous steps and thus requires less radical regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
